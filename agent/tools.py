import json
import os
import asyncio
import logging
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import aiosmtplib
from dotenv import load_dotenv
load_dotenv()
from langchain_ollama import OllamaEmbeddings
from utils.database import get_pg_connection, fetchall, get_redis_client
from agent.state import State

OLLAMA_HOST = os.getenv("OLLAMA_HOST")
embedd = OllamaEmbeddings(model="bge-m3:latest", base_url=OLLAMA_HOST
)
import traceback

logger = logging.getLogger(__name__)
VERIFY_TOKEN = os.getenv("VERIFY_TOKEN")
PAGE_ACCESS_TOKEN = os.getenv("PAGE_ACCESS_TOKEN")
GRAPH_API_URL = "https://graph.facebook.com/v21.0/me/messages"
REDIS_URL = os.getenv("REDIS_URL")
PG_HOST_AI = "localhost"
PG_PORT_AI = 5432
PG_USER= os.getenv("DB_USERNAME")
PG_PASS= os.getenv("DB_PASSWORD")

# Email configuration
SMTP_HOST = os.getenv("SMTP_HOST", "smtp.gmail.com")
SMTP_PORT = int(os.getenv("SMTP_PORT", "587"))
SMTP_USERNAME = os.getenv("SMTP_USERNAME")
SMTP_PASSWORD = os.getenv("SMTP_PASSWORD")
EMERGENCY_EMAIL_RECIPIENTS = os.getenv("EMERGENCY_EMAIL_RECIPIENTS", "evkingwind9218@gmail.com,thanhtam852009@gmail.com").split(",")
async def embedding(text):
    """Async wrapper for embedding to avoid blocking"""
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(None, embedd.embed_query, text)

async def send_emergency_email(user_id: str, user_message: str, emotion_status: str, problem: str, urgency: str):
    """G·ª≠i email th√¥ng b√°o kh·∫©n c·∫•p t·ªõi c√°c gi√°o vi√™n ph·ª• tr√°ch"""
    if not SMTP_USERNAME or not SMTP_PASSWORD:
        logger.warning("‚ö†Ô∏è Email configuration not set. Skipping email notification.")
        return False
    
    try:
        # T·∫°o email content
        subject = f"üö® C·∫¢NH B√ÅO KH·∫®N C·∫§P - H·ªçc sinh c·∫ßn h·ªó tr·ª£ ngay l·∫≠p t·ª©c"
        
        html_body = f"""
        <html>
        <head>
            <style>
                body {{ font-family: Arial, sans-serif; line-height: 1.6; }}
                .container {{ max-width: 600px; margin: 0 auto; padding: 20px; }}
                .header {{ background-color: #dc3545; color: white; padding: 20px; border-radius: 5px; }}
                .content {{ background-color: #f8f9fa; padding: 20px; margin-top: 20px; border-radius: 5px; }}
                .warning {{ background-color: #fff3cd; border-left: 4px solid #ffc107; padding: 15px; margin: 15px 0; }}
                .info-row {{ margin: 10px 0; }}
                .label {{ font-weight: bold; color: #495057; }}
                .value {{ color: #212529; }}
                .footer {{ margin-top: 20px; padding-top: 20px; border-top: 1px solid #dee2e6; color: #6c757d; font-size: 12px; }}
            </style>
        </head>
        <body>
            <div class="container">
                <div class="header">
                    <h2>üö® C·∫¢NH B√ÅO KH·∫®N C·∫§P</h2>
                    <p>H·ªá th·ªëng AI Mimi ph√°t hi·ªán h·ªçc sinh c·∫ßn h·ªó tr·ª£ t√¢m l√Ω kh·∫©n c·∫•p</p>
                </div>
                
                <div class="content">
                    <h3>Th√¥ng tin h·ªçc sinh:</h3>
                    <div class="info-row">
                        <span class="label">User ID:</span>
                        <span class="value">{user_id}</span>
                    </div>
                    <div class="info-row">
                        <span class="label">V·∫•n ƒë·ªÅ ƒëang g·∫∑p ph·∫£i:</span>
                        <span class="value">{problem}</span>
                    </div>
                    <div class="info-row">
                        <span class="label">Tr·∫°ng th√°i c·∫£m x√∫c:</span>
                        <span class="value">{emotion_status}</span>
                    </div>
                    <div class="info-row">
                        <span class="label">M·ª©c ƒë·ªô kh·∫©n c·∫•p:</span>
                        <span class="value" style="color: #dc3545; font-weight: bold;">{urgency.upper()}</span>
                    </div>
                    
                    <div class="warning">
                        <h4>‚ö†Ô∏è N·ªôi dung tin nh·∫Øn:</h4>
                        <p>"{user_message}"</p>
                    </div>
                    
                    <div style="background-color: #d1ecf1; border-left: 4px solid #0c5460; padding: 15px; margin: 15px 0;">
                        <h4>üìã H√†nh ƒë·ªông c·∫ßn th·ª±c hi·ªán:</h4>
                        <ul>
                            <li>Li√™n h·ªá ngay v·ªõi h·ªçc sinh ho·∫∑c gia ƒë√¨nh</li>
                            <li>ƒê√°nh gi√° m·ª©c ƒë·ªô r·ªßi ro tr·ª±c ti·∫øp</li>
                            <li>Xem x√©t c·∫ßn thi·∫øt can thi·ªáp chuy√™n m√¥n</li>
                            <li>Th√¥ng b√°o cho Ban Gi√°m hi·ªáu n·∫øu c·∫ßn</li>
                        </ul>
                    </div>
                    
                    <p style="color: #856404; background-color: #fff3cd; padding: 10px; border-radius: 5px;">
                        <strong>L∆∞u √Ω:</strong> Email n√†y ƒë∆∞·ª£c g·ª≠i t·ª± ƒë·ªông t·ª´ h·ªá th·ªëng AI Mimi. 
                        Vui l√≤ng x·ª≠ l√Ω trong th·ªùi gian s·ªõm nh·∫•t.
                    </p>
                </div>
                
                <div class="footer">
                    <p>Email n√†y ƒë∆∞·ª£c g·ª≠i t·ª´ H·ªá th·ªëng Tr·ª£ l√Ω AI Mimi - THCS Gia Thanh</p>
                    <p>Th·ªùi gian: {asyncio.get_event_loop().time()}</p>
                    <p>Hotline h·ªó tr·ª£: C√¥ Th√∫y (0962186108) | C√¥ Tr√¢m (0915266338)</p>
                </div>
            </div>
        </body>
        </html>
        """
        
        # T·∫°o message
        message = MIMEMultipart("alternative")
        message["Subject"] = subject
        message["From"] = SMTP_USERNAME
        message["To"] = ", ".join(EMERGENCY_EMAIL_RECIPIENTS)
        
        # Attach HTML content
        html_part = MIMEText(html_body, "html", "utf-8")
        message.attach(html_part)
        
        # G·ª≠i email b·∫•t ƒë·ªìng b·ªô
        await aiosmtplib.send(
            message,
            hostname=SMTP_HOST,
            port=SMTP_PORT,
            username=SMTP_USERNAME,
            password=SMTP_PASSWORD,
            start_tls=True,
        )
        
        logger.info(f"‚úÖ ƒê√£ g·ª≠i email kh·∫©n c·∫•p cho user {user_id} t·ªõi {len(EMERGENCY_EMAIL_RECIPIENTS)} ng∆∞·ªùi nh·∫≠n")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå L·ªói khi g·ª≠i email kh·∫©n c·∫•p: {str(e)}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        return False

async def get_user_information(state: State):
    """
        This node must be done first before get deep chat with person
        Short-term memory will be loaded all from long-term memory to gain insights
        
    """
    redis = await get_redis_client()
    user_id = state["conversation"]["user_id"]
    messages = state["conversation"]["messages"]
    
    problem = state.get("user_emotion",{}).get("problem", None)
    query = """
        SELECT * FROM user_memory
        WHERE user_id = $1
    """
    user = await fetchall(query, user_id)
    if user:
        # Cho v√†o trong GraphRAG
        await redis.set(f"memory:{user_id}:preferences", user.preferences, ex=3*60*60)
        await redis.set(f"memory:{user_id}:hates", user.hates, ex=3*60*60)
    if (not user and not problem) or not problem:        
        return {
            **state,
            "conversation":{
                "user_id": user_id,
                "messages": messages,
                "is_new_user": True
            },
            "next_step":"clarify",
            "user_emotion":{
                "problem":"MUST CLARIFY MORE INFORMATION."
            }
        }
    return {**state}
    
async def update_cache(state: State):
    bot_plan = state["bot_plan"]
    is_new_user = state["conversation"].get("is_new_user", True)
    current_risk = state["risk"]
    current_emotion = state['user_emotion']
    user_id = state["conversation"]["user_id"]
    # L·∫•y t·∫•t c·∫£ messages t·ª´ state (ƒë√£ ƒë∆∞·ª£c reducer gi·ªõi h·∫°n 5 messages)
    current_messages = state["conversation"]["messages"]
    redis = await get_redis_client()
    
    summary_data = await redis.get(f"summary:{user_id}")
    conversation_data = await redis.get(f"past:conversation:{user_id}")
    
    # Merge messages c≈© v√† m·ªõi, gi·ªØ t·ªëi ƒëa 5 messages g·∫ßn nh·∫•t
    if conversation_data:
        try:
            conversation_json = json.loads(conversation_data)
            # L·∫•y messages c≈©
            old_messages = conversation_json.get("messages", [])
            # Merge v·ªõi messages m·ªõi
            all_messages = old_messages + current_messages
            # Ch·ªâ gi·ªØ 5 messages g·∫ßn nh·∫•t
            conversation_json["messages"] = all_messages[-5:]
        except json.JSONDecodeError:
            # N·∫øu parse l·ªói, t·∫°o m·ªõi v·ªõi 5 messages g·∫ßn nh·∫•t
            conversation_json = {"messages": current_messages[-5:]}
    else:
        # Kh√¥ng c√≥ history c≈©, t·∫°o m·ªõi v·ªõi 5 messages g·∫ßn nh·∫•t
        conversation_json = {"messages": current_messages[-5:]}

    context_json = json.loads(summary_data)
    
    bot_plan_verified = {
        "problem": state["user_emotion"].get("problem",""),
        "bot_plan": state["bot_plan"],
        "confidence_score": state["confidence_score"],
        "risk":state.get("risk", {}),
        "language_signals": context_json.get("key_context")
    }
    payload = {
        "bot_plan": bot_plan,
        "is_new_user": is_new_user,
        "past_risk": current_risk,
        "past_emotion": current_emotion
    }
    # ƒêi·ªÉm c·∫ßn c·∫£i thi·ªán
    # T·∫•t c·∫£ tin nh·∫Øn gi·ªØa staff, user, v√† system s·∫Ω ƒë∆∞·ª£c l∆∞u l·∫°i v√† ƒë√°nh gi√° RHLF th√¥ng qua ph∆∞∆°ng th·ª©c post ƒë·ªÉ g·ª≠i t·ªõi server kh√°c ƒë·ªÉ update long term memory v·ªÅ knowlege base
    # RHLF s·∫Ω t·∫°o m·ªôt server kh√°c ri√™ng ƒë·ªÉ c·∫≠p nh·∫≠t d·ªØ li·ªáu, v√† ch√∫ng ta s·∫Ω g·ª≠i l·∫°i method post t·ªõi ƒë√≥
    await redis.set(f"past:rhlf:{user_id}",json.dumps(bot_plan_verified, ensure_ascii=False), ex=60*60)
    await redis.set(f"past:notes:{user_id}", json.dumps(payload, ensure_ascii=False), ex=60*60)
    await redis.set(f"past:conversation:{user_id}",json.dumps(conversation_json, ensure_ascii=False), ex=60*60)
    await redis.set(f"current:state:{user_id}", json.dumps(state, ensure_ascii=False), ex=60*60)
    return {}
def strip_markdown_json(content: str) -> str:
    """Remove markdown code block wrapper from LLM JSON response"""
    if not content:
        return "{}"
    
    # Remove ```json ... ``` or ``` ... ```
    content = content.strip()
    if content.startswith("```"):
        # Find first newline after ```
        first_newline = content.find('\n')
        if first_newline != -1:
            content = content[first_newline+1:]
        # Remove trailing ```
        if content.endswith("```"):
            content = content[:-3]
        return content.strip()
    else: return content
async def get_emotion(state: State):
    """
        This node will be done initially to get first wanting from user,
        source of solutions later on 
        Design Doc: 
        Emotion detection is signal extraction, not diagnosis.
        Risk and action decisions must be separated.
    """
    from langchain_openai import ChatOpenAI
    llm = ChatOpenAI(
        model="gpt-4.1-mini",
        temperature=0.5,
        api_key=os.getenv("OPENAI_API_KEY")
    )
    redis = await get_redis_client()
    messages = state["conversation"]["messages"][-1]["content"]
    user_id = state['conversation']["user_id"]
    conv_summary = await redis.get(f"summary:{user_id}")
    if conv_summary:
        try:
            prev = json.loads(conv_summary)
            prev_intense = prev.get("intense")
        except:
            prev_intense = None
    emotion_prompt = f"""
       ### TASK
        Analyze the emotional signal of the LATEST message provided below.

        ### INPUT
        - Message: "{messages}"
        - Previous Context Intense: "{prev_intense}"

        ### CLASSIFICATION GUIDELINES
        1. **Status**: joy, sadness, fear, disgust, anger, surprise, uncertain.
        - If message is vague (e.g., "hmm", "ok") -> status: "uncertain".
        - If greeting -> status: "joy".
        2. **Urgency**:
        - "normal": Casual conversation, venting without danger.
        - "watch": Deep sadness, anger, mentions of hopelessness.
        - "immediate": Explicit self-harm (cutting, suicide), violence, or clear crisis.
        3 **Problem (CRITICAL - MUST BE IN VIETNAMESE)**: 
           - Extract the specific subject, struggle, or topic the user is talking about in **VIETNAMESE** (Ti·∫øng Vi·ªát).
           - Examples of valid problems:
                                                                                                             * "kh√≥ khƒÉn trong v·∫•n ƒë·ªÅ to√°n h·ªçc","m·∫•t g·ªëc to√°n h√¨nh","c·∫£m th·∫•y √°p l·ª±c trong hb·ªçc t·∫≠p","√°p l·ª±c thi c·ª≠", ..v.v (Academic)
             * "c·∫£m th·∫•y b·ªã b·∫°n b√® t·∫©y chay", "g·∫∑p kh√≥ khƒÉn trong k·∫øt n·ªëi v·ªõi b·∫°n b√®", "kh√≥ khƒÉn ƒë·ªÉ h√≤a ƒë·ªìng", "kh√≥ khƒÉn trong giao ti·∫øp v·ªõi ph·ª• huynh", v.v (Social)
             * "c·∫£m th·∫•y c√¥ ƒë∆°n", "crush kh√¥ng t√≠ch", "c√£i nhau v·ªõi b·ªë m·∫π" (Emotional), v.v
             * "c·∫ßn l·ªùi khuy√™n trong h·ªçc t·∫≠p", "c·∫ßn s·ª± h∆∞·ªõng d·∫´n ƒë·ªÉ tr·ªü n√™n th√†nh c√¥ng", v.v (Request)
           - ONLY use "MUST CLARIFY" if the message is purely a greeting (e.g. "Hello") or completely vague (e.g. "I'm sad" without reason).

        ### SAFETY RULES
        - Do NOT diagnose mental disorders.
        - If user mentions "die", "kill", "suicide", "hurt myself" -> Urgency MUST be "immediate".
        - Urgency cannot be lower than Previous Context Intense (unless topic changed).

        ### OUTPUT JSON
        {{
            "status": "...",
            "problem": "...",
            "metadata": {{ "trigger": "...", "context": "..." }},
            "self_harm": true/false,
            "violence": true/false,
            "urgency": "normal | watch | immediate",
            "confidence_score": 0.0 to 1.0
    }}
    """
    try:
        response = await llm.ainvoke(emotion_prompt)
        cleaned_content = strip_markdown_json(response.content)
        data = json.loads(cleaned_content)
        response_urgency = data.get("urgency", "normal")
        logger.info(f"‚úÖ CAUGHT PROBLEM: {data.get('problem', '')}")
        if data.get("self_harm") or data.get("violence"):
            response_urgency = "immediate"
        return {
            **state,
            "user_emotion": {
                "status": data.get("status", "uncertain"),
                "problem": data.get("problem", ""),
                "metadata": data.get("metadata", {
                    "trigger": "",
                    "duration": "",
                    "context": ""
                }),
            },
            "risk": {
                "self_harm": data.get("self_harm", False),
                "violence": data.get("violence", False),
                "urgency": response_urgency
            },
            "confidence_score": float(data.get("confidence_score", 0.3) )
        }

    except Exception as e:
        logger.error(f"‚ùå [get_emotion] Error: {str(e)}")
        return {
            "user_emotion": {
                "status": "uncertain",
                "problem": "",
                "metadata": {
                    "trigger": "",
                    "duration": "",
                    "context": ""
                },
                "crisis_level": "low",
            },
            "confidence_score": 0.1
        }
SIM_THRESHOLD = 0.78

async def retrieve_risk_assessment(state: State):
    query = """
        SELECT
            problem,
            solution,
            tone,
            must_not_do,
            level,
            language_signals,
            self_harm,
            violence,
            urgency,
            1 - (embedding <=> $1::vector) AS similarity
        FROM bot_knowledge
        ORDER BY embedding <=> $1::vector
        LIMIT 1
    """

    # ---- Ensure DB connection ----
    await get_pg_connection()

    problem = state["user_emotion"].get("problem")

    # ---- Hard guard: no clear problem ----
    if not problem or problem == "MUST CLARIFY MORE INFORMATION.":
        return {
            **state,
            "user_emotion": {
                **state["user_emotion"],
                "is_new_problem": False
            }
        }

    vector = await embedding(problem)
    rows = await fetchall(query, str(vector))

    # ---- No retrieval result ----
    if not rows:
        return {
            **state,
            "user_emotion": {
                **state["user_emotion"],
                "is_new_problem": True
            }
        }

    result = rows[0]
    similarity = result.get("similarity", 0)

    # ---- üî• CORE SAFETY: similarity too low ‚Üí IGNORE ----
    if similarity < SIM_THRESHOLD:
        return {
            **state,
            "user_emotion": {
                **state["user_emotion"],
                "is_new_problem": True
            },
            "rag_meta": {
                "ignored": True,
                "similarity": similarity
            }
        }

    # ---- Accepted retrieval ----
    crisis_dict = {
        "0": "low",
        "1": "medium",
        "2": "high",
        "3": "critical"
    }
    # ‚ö†Ô∏è KH√îNG save solution ·ªü ƒë√¢y - ch·ªâ save khi ƒë√£ d√πng th·∫≠t trong generate_response
    return {
        **state,
        "bot_plan": {
            "solution": result["solution"],
            "must_not_do": result["must_not_do"],
            "tone": result["tone"]
        },
        "user_emotion":{
            **state["user_emotion"],
            "is_new_problem": False,
            "crisis_level": crisis_dict.get(str(result["level"]), "low"),
        },
        "risk": {
            "self_harm": result["self_harm"],
            "violence": result["violence"],
            "urgency": result.get("urgency", "normal")
        },
        "rag_meta": {
            "ignored": False,
            "similarity": similarity
        },
        "confidence_score": 1
    }


async def guest_risk_assesment(state: State):
    should_guest = state["user_emotion"].get("is_new_problem", True)
    if should_guest:
        confidence_score = state["confidence_score"]
        risk_violence = state["risk"]["violence"]
        risk_self_harm = state["risk"]["self_harm"]
        emotion_status = state["user_emotion"]["status"]
        if risk_self_harm and confidence_score >= 0.7 and emotion_status in ["sadness", "fear"]:
            return {
                **state,
                "risk":{
                    **state["risk"],
                    "urgency":"immediate"
                },
                "user_emotion":{
                    **state["user_emotion"],
                    "crisis_level":"critical"
                }
            }
        elif (risk_self_harm or risk_violence) and confidence_score >= 0.6 and emotion_status in ["sadness", "fear", "anger"]:
            return {
                **state,
                "risk":{
                    **state["risk"],
                    "urgency":"watch"
                },
                "user_emotion":{
                    **state["user_emotion"],
                    "crisis_level":"high"
                }   
            }
        elif (risk_self_harm or risk_violence) and confidence_score >= 0.4 and emotion_status in ["sadness", "fear", "anger"]:
            # Can phai validate them cam xuc
            return {
                **state,
                "risk":{
                    **state["risk"],
                    "urgency":"watch"
                },
                "user_emotion":{
                    **state["user_emotion"],
                    "crisis_level":"medium"
                }
            }
        else:
            return {
                **state,
                "risk":{
                    **state["risk"],
                    "urgency": "normal"
                },
                "user_emotion":{
                    **state["user_emotion"],
                    "crisis_level":"low"
                }
            }
    else:
        return {**state}
async def route_after_decision(state: State):
    urgency_res = await is_urgent(state)
    if urgency_res == "response_emergency":
        return "response_emergency"
    else: 
        plan_res = await should_rotate_plan(state)
        return plan_res
async def bot_planning(state: State):
    from langchain_openai import ChatOpenAI
    llm = ChatOpenAI(
        model="gpt-4.1-mini",
        temperature=0.3,
        api_key=os.getenv("OPENAI_API_KEY")
    )
    redis = await get_redis_client()
    
    user_id = state["conversation"]["user_id"]
    
    # Get user context
    user_message = state["conversation"]["messages"][-1]["content"]
    emotion_status = state["user_emotion"]["status"]
    problem = state["user_emotion"]["problem"]
    crisis_level = state["user_emotion"].get("crisis_level", "low")
    metadata = state["user_emotion"]["metadata"]
    confidence_score = state["confidence_score"]
    urgency = state["risk"]["urgency"]
    self_harm = state["risk"]["self_harm"]
    violence = state["risk"]["violence"]
    
    # Get conversation summary
    conv_summary = await redis.get(f"summary:{user_id}")
    summary_data = json.loads(conv_summary) if conv_summary else {}
    logger.info(f"[bot_planning] PREVIOUS SUMM: {summary_data}")
    # Get user preferences if available
    user_preferences = await redis.get(f"memory:{user_id}:preferences")
    user_hates = await redis.get(f"memory:{user_id}:hates")
    plan_prompt = f"""
        You are a compassionate conversation planner for an AI assistant supporting teenagers (10-16 years old).
        Your task is to create a structured response plan based on the user's emotional state and context.

        ## INPUT DATA:

        **User Message:**
        "{user_message}"

        **Emotional Analysis:**
        - Status: {emotion_status}
        - Problem: {problem}
        - Crisis Level: {crisis_level}
        - Confidence Score: {confidence_score}
        - Trigger: {metadata.get('trigger', 'N/A')}
        - Duration: {metadata.get('duration', 'N/A')}
        - Context: {metadata.get('context', 'N/A')}

        **Risk Assessment:**
        - Urgency: {urgency}
        - Self-harm risk: {self_harm}
        - Violence risk: {violence}

        **Conversation Context:**
        {json.dumps(summary_data, ensure_ascii=False, indent=2) if summary_data else "No previous context"}

        **User Profile:**
        - Preferences: {user_preferences if user_preferences else "Unknown"}
        - Dislikes: {user_hates if user_hates else "Unknown"}

        ---

        ## YOUR TASK:

        Create a JSON Conversation plan that includes:

        1. **Solution Strategy**: What approach should the bot take?
        - Options: "empathize_first", "provide_guidance", "ask_clarifying_questions", "offer_resources", "gentle_redirect", "validate_feelings"

        2. **Tone**: How should the bot communicate?
        - Options: "warm_supportive", "calm_reassuring", "gentle_curious", "cheerful_encouraging", "serious_concerned", "playful_light", "encouraging_sister", "gentle_protective"

        3. **Must Not Do**: What should the bot absolutely avoid?
        - Be specific based on the emotional state and risks
        RETURN JSON ONLY.
   """
    try:
        response = await llm.ainvoke(plan_prompt)
        cleaned_content = strip_markdown_json(response.content)
        plan_data = json.loads(cleaned_content)
        logger.info(f"‚úÖ RECEIVED [bot_planning]: {plan_data}")
        
        return {
            **state,
            "bot_plan": {
                "solution": plan_data.get("solution", "validate_feelings"),
                "tone": plan_data.get("tone", "warm_supportive"),
                "must_not_do": plan_data.get("must_not_do", []),
            }
        }
    except Exception as e:
        logger.error(f"[bot_planning] Error: {str(e)}")
        return {
            **state,
            "bot_plan": {
                "solution": "validate_feelings",
                "tone": "warm_supportive",
                "must_not_do": ["dismiss feelings", "give medical advice", "make promises"]
            }
        }
async def should_rotate_plan(state: State):
    bot_plan = state.get("bot_plan", None)
    user_id = state["conversation"]["user_id"]
    redis = await get_redis_client()
    key = await redis.get(f"summary:{user_id}")
    response = json.loads(key)
    print("‚úÖ[SHOULD ROTATE PLAN] RECEIVED",bot_plan)
    if bot_plan is None: #or response["status"] == "changed":
        return "bot_planning"
    else:
        return "gen_response"
async def decide_next_step(state: State):
    redis = await get_redis_client()
    crisis_level = state["user_emotion"].get("crisis_level","low")
    user_id = state["conversation"]["user_id"]
    urgency = state["risk"]["urgency"]
    confidence_score = state["confidence_score"]
    self_harm = state["risk"]["self_harm"]
    violence = state["risk"]["violence"]
    problem = state["user_emotion"]["problem"]
    emotion_status = state["user_emotion"]["status"]
    summary_data = json.loads(await redis.get(f"summary:{user_id}"))
    if summary_data.get("intense") == "growing" and problem:
        return {**state, "next_step": "guide"}
    if (urgency == "immediate" and crisis_level in ["critical", "high"]) and confidence_score >= 0.7:
        return {
            **state,
            "next_step":"escalate"
        }
    elif urgency == "watch" and crisis_level == "high" and confidence_score >= 0.6:
        return {
            **state,
            "next_step":"guide"
        }  
    elif crisis_level == 'medium' and confidence_score >= 0.5:
        if self_harm or violence:
            return {
                **state,
                "next_step":"guide"
            }
        else:
            return {
                **state,
                "next_step":"comfort"
            } 
    elif confidence_score < 0.5 or emotion_status == "uncertain":
        if not problem or problem == "MUST CLARIFY MORE INFORMATION.":
            return {
                **state,
                "next_step": "clarify"
            }
    else:
        return {
            **state,
            "next_step":"listen"
        }
async def summary_conv_history(state: State):
    """
    Conversation summary is intent memory, not transcript memory.
    Assistant messages are never part of long-term context.
    L·∫•y state t·ª´ Redis v√† c·∫≠p nh·∫≠t n·∫øu l√† l·∫ßn th·ª© 2 ng∆∞·ªùi d√πng ch·∫°y.
    """
    from langchain_openai import ChatOpenAI
    llm = ChatOpenAI(
        model="gpt-4.1-mini",
        temperature=0.2, 
        api_key=os.getenv("OPENAI_API_KEY")
    )
    redis = await get_redis_client()
    user_id = state["conversation"]["user_id"]
    messages = state["conversation"]["messages"]
    
    # ===== L·∫•y state c≈© t·ª´ Redis (n·∫øu c√≥) =====
    previous_state_data = await redis.get(f"current:state:{user_id}")
    is_returning_user = False
    
    if previous_state_data:
        try:
            previous_state = json.loads(previous_state_data)
            is_returning_user = True
            logger.info(f"[summary_conv_history] ‚úÖ T√¨m th·∫•y state c≈© cho user {user_id}")
            
            # Merge c√°c th√¥ng tin t·ª´ state c≈© n·∫øu c·∫ßn thi·∫øt
            if "user_emotion" in previous_state and not state.get("user_emotion"):
                state["user_emotion"] = previous_state["user_emotion"]
            
            if "risk" in previous_state and not state.get("risk"):
                state["risk"] = previous_state["risk"]
            
            if "bot_plan" in previous_state and not state.get("bot_plan"):
                state["bot_plan"] = previous_state["bot_plan"]
                
            logger.info(f"[summary_conv_history] üîÑ ƒê√£ merge th√¥ng tin t·ª´ state c≈©")
        except json.JSONDecodeError as e:
            logger.warning(f"[summary_conv_history] ‚ö†Ô∏è Kh√¥ng parse ƒë∆∞·ª£c state c≈©: {e}")
            is_returning_user = False
    else:
        logger.info(f"[summary_conv_history] ‚ÑπÔ∏è User {user_id} l·∫ßn ƒë·∫ßu ti√™n ho·∫∑c kh√¥ng c√≥ state c≈©")
    
    # Parse messages if string
    if isinstance(messages, str):
        try:
            messages = json.loads(messages)
        except json.JSONDecodeError:
            messages = []
    
    # Ensure messages is a list
    if not isinstance(messages, list):
        messages = []
    
    # Extract CH·ªà user messages t·ª´ to√†n b·ªô messages (ƒë√£ ƒë∆∞·ª£c reducer gi·ªØ l·∫°i 5 c√°i g·∫ßn nh·∫•t)
    recent_user_msgs = []
    for m in messages:
        if isinstance(m, dict):
            # Ch·ªâ l·∫•y user messages
            if m.get("role") == "user" and m.get("content"):
                recent_user_msgs.append(m["content"])
    
    # N·∫øu kh√¥ng l·∫•y ƒë∆∞·ª£c tin nh·∫Øn n√†o, l·∫•y tin nh·∫Øn cu·ªëi c√πng
    if not recent_user_msgs and messages:
        last_msg = messages[-1]
        if isinstance(last_msg, dict) and "content" in last_msg:
            recent_user_msgs = [last_msg["content"]]
    
    lastest_message = " | ".join(recent_user_msgs) if recent_user_msgs else ""
    recent_msgs = await redis.get(f"past:conversation:{user_id}")
    logger.info(f"[summary_conv_history] üì® Recent user messages: {recent_msgs}")
    logger.info(f"[summary_conv_history] üìù Current messages: {lastest_message}")
    logger.info(f"[summary_conv_history] üî¢ Is returning user: {is_returning_user}")
    last_summary = await redis.get(f"summary:{user_id}")
    prev_intense = None
    if last_summary:
        try:
            prev = json.loads(last_summary)
            prev_intense = prev.get("intense")
        except:
            prev_intense = None

    new_summary_prompt = f"""
    ### SYSTEM ROLE
    You are the MEMORY MANAGER. Update the conversation summary based on logic below.

    ### INPUT
    - Previous Summary: {json.dumps(last_summary, ensure_ascii=False) if last_summary else "None"}
    - User Message: "{lastest_message}"
    
    ### LOGIC FOR "STATUS" & "INTENSE" (CRITICAL)
    
    1. **CONTINUING (Most Common)**:
       - User answers a previous question (e.g., Bot: "Which part?", User: "Trigonometry").
       - User gives more details on the SAME broad topic (e.g., Math -> Geometry -> Trigonometry).
       - User is venting/complaining about the SAME issue.
       -> ACTION: Set status = "continuing". Increase 'intense' (starting -> growing).

    2. **CHANGED**:
       - User explicitly stops the current topic (e.g., "Enough about math, let's talk about games").
       - User starts a completely UNRELATED topic.
       -> ACTION: Set status = "changed". Reset 'intense' = "starting".

    ### LOGIC RULES
    1. IF Previous Summary is NULL -> Status = "changed", Intense = "starting".
    2. IF User switches topic -> Status = "changed", Intense = "starting".
    3. IF User continues topic -> Status = "continuing".
       - AND user provides more detail -> Intense = "growing".
       - AND user screams/cries/demands -> Intense = "request_high_urgency".
    4. **IMPORTANT**: Intense can NEVER decrease within the same topic.

    ### OUTPUT JSON
    {{
        "reasoning": "Explain why it is CONTINUING or CHANGED. Did user answer a question?",
        "intent": "Update intent (e.g., seeking help with trigonometry)",
        "main_topic": "...",
        "intense": "starting | growing | request_high_urgency",
        "status": "continuing | changed",
        "key_context": ["User struggles with Trigonometry basics"],
        "confidence_score": 0.95
    }}
    """
    try:
        response = await llm.ainvoke(new_summary_prompt)
        logger.debug(f"[summary_conv_history] Response: {response.content}")
        cleaned_content = strip_markdown_json(response.content)
        summary_data = json.loads(cleaned_content)
        
        # L∆∞u summary m·ªõi v√†o Redis
        summary_to_save = {
            "intent": summary_data.get("intent",""),
            "intense": summary_data.get("intense",""),
            "main_topic": summary_data.get("main_topic",""),
            "status": summary_data.get("status","continuing"),
            "key_context": summary_data.get("key_context",[]),
            "is_returning_user": is_returning_user
        }
        
        await redis.set(
            f"summary:{user_id}",
            json.dumps(summary_to_save, ensure_ascii=False),
            ex=60*60
        )
        
        # C·∫≠p nh·∫≠t state m·ªõi v·ªõi th√¥ng tin returning user
        updated_state = {
            **state,
            "confidence_score": summary_data.get("confidence_score", 0.3)
        }
        
        # N·∫øu l√† returning user, th√™m flag v√†o conversation
        if is_returning_user:
            updated_state["conversation"]["is_new_user"] = False
        
        logger.info(f"[summary_conv_history] ‚úÖ ƒê√£ c·∫≠p nh·∫≠t summary cho user {user_id}")
        logger.info(f"[summary_conv_history] üìä Status: {summary_data.get('status')}, Intense: {summary_data.get('intense')}")
        
        return updated_state
    except Exception as e:
        logger.error(f"[summary_conv_history] Error: {str(e)}")
        logger.error(f"[summary_conv_history] Error type: {type(e).__name__}")
        logger.error(f"[summary_conv_history] Error details: {repr(e)}")
        logger.error(f"[summary_conv_history] Traceback:\n{traceback.format_exc()}")
        return state
async def is_information_loaded(state: State):
    user_id = state["conversation"]["user_id"]
    redis = await get_redis_client() 
    if await redis.get(f"memory:{user_id}:preferences"):
        return "should_get_emotion"
    else:
        return "get_user_information" 
async def should_get_emotion(state: State):
    redis = await get_redis_client()
    try:
        user_id = state["conversation"]["user_id"]
        last_summary = await redis.get(f"summary:{user_id}")
        summary_data = json.loads(last_summary)
        if summary_data["status"] == "changed":
            return "get_emotion"
        else:
            return "retrieve_risk_assessment"
    except Exception as e:
        logger.error(f"L·ªói t·∫°i node should_get_emotion: {str(e)}")
        return "get_emotion"
async def generate_response(state: State):
    from langchain_openai import ChatOpenAI
    
    llm = ChatOpenAI(
        model="gpt-4.1-mini",
        temperature=0.7,
        api_key=os.getenv("OPENAI_API_KEY")
    )
    redis = await get_redis_client()
    user_id = state["conversation"]["user_id"]
    
    # Extract all context
    user_message = state["conversation"]["messages"][-1]["content"]
    emotion_status = state["user_emotion"]["status"]
    problem = state["user_emotion"]["problem"]
    crisis_level = state["user_emotion"].get("crisis_level", "low")
    next_step = state.get("next_step", "listen")
    
    # Get bot plan
    bot_plan = state.get("bot_plan", {})
    solution = bot_plan.get("solution", "validate_feelings")
    tone = bot_plan.get("tone", "warm_supportive")
    must_not_do = bot_plan.get("must_not_do", [])
    
    # Get conversation summary
    conv_summary = await redis.get(f"summary:{user_id}")
    summary_data = json.loads(conv_summary) if conv_summary else {}
    
    
    # Get RAG solution (full text t·ª´ database, kh√¥ng ph·∫£i strategy name)
    rag_solution = bot_plan.get("solution", "")
    
    # Get last solution ƒë√£ d√πng (ƒë·ªÉ tr√°nh l·∫∑p l·∫°i)
    last_solution_bytes = await redis.get(f"rag:solution:{user_id}")
    last_solution = last_solution_bytes if last_solution_bytes else None
    
    # N·∫øu solution n√†y ƒë√£ d√πng r·ªìi, b·ªè qua (ƒë·ªÉ LLM t·ª± s√°ng t·∫°o)
    if last_solution and rag_solution and last_solution.strip() == rag_solution.strip():
        rag_solution = ""  # ƒê·ªÉ tr·ªëng ƒë·ªÉ LLM t·ª± nghƒ©

    if next_step == "clarify":
        system_instruction = """B·∫°n l√† Mimi - tr·ª£ l√Ω ·∫£o th√¢n thi·ªán c·ªßa tr∆∞·ªùng THCS Gia Thanh.
        Nhi·ªám v·ª•: ƒê·∫∑t c√¢u h·ªèi M·ªû ƒë·ªÉ hi·ªÉu r√µ h∆°n v·∫•n ƒë·ªÅ em.

        Quy t·∫Øc:
        - D√πng gi·ªçng ƒëi·ªáu t√≤ m√≤, th√¢n thi·ªán
        - H·ªèi 1-2 c√¢u ng·∫Øn g·ªçn
        - Kh√¥ng gi·∫£ ƒë·ªãnh v·∫•n ƒë·ªÅ
        - Kh√¥ng √°p ƒë·∫∑t c·∫£m x√∫c
        - D√πng emoji ph√π h·ª£p D·ª∞A TR√äN C·∫¢M X√öC hi·ªán t·∫°i c·ªßa EM.

        V√≠ d·ª• t·ªët:
        "M√¨nh c√≥ th·ªÉ k·ªÉ th√™m v·ªÅ chuy·ªán ƒë√≥ ƒë∆∞·ª£c kh√¥ng? ü§î"
        "Em c·∫£m th·∫•y nh∆∞ th·∫ø n√†o v·ªÅ vi·ªác n√†y? üí≠"
    """

    elif next_step == "guide":
        system_instruction = f"""You are Mimi, a supportive, empathetic, and gentle older sister (big sister figure) for a middle school student (10-15 years old).
    ### C√ÅCH TR·∫¢ L·ªúI
        - ƒê·ª´ng ch·ªâ copy-paste b√≠ k√≠p. H√£y bi·∫øn n√≥ th√†nh l·ªùi th·ªß th·ªâ.
        - Thay v√¨ n√≥i: "B∆∞·ªõc 1 l√† quan s√°t", h√£y n√≥i: "M·∫πo nh·ªè n√®, em th·ª≠ ngh√≠a xem b·∫°n ·∫•y ƒëang c·∫ßm m√≥n ƒë·ªì g√¨ hay hay kh√¥ng..."
        - Lu√¥n k·∫øt th√∫c b·∫±ng m·ªôt c√¢u h·ªèi k√≠ch th√≠ch h√†nh ƒë·ªông nh·ªè: "Mai em c√≥ d√°m th·ª≠ kh√¥ng?", "Em th·∫•y chi√™u n√†y c√≥ kh·∫£ thi kh√¥ng?"
    ### CURRENT SITUATION
    - User Emotion: {emotion_status} (Crisis Level: {crisis_level})
    - Problem: {problem}
    - Strategy: {solution}
    - Tone: {tone}
    ### REMEMBER
    NHI·ªÜM V·ª§:
        1. ƒê·ª´ng h·ªèi "ph·∫ßn n√†o" n·ªØa n·∫øu user n√≥i "kh√¥ng hi·ªÉu g√¨ c·∫£".
        2. H√£y ƒë·ªÅ xu·∫•t m·ªôt b∆∞·ªõc nh·ªè nh·∫•t, d·ªÖ nh·∫•t.### LOGIC RULES
    1. IF Previous Summary is NULL -> Status = "changed", Intense = "starting".
    2. IF User switches topic -> Status = "changed", Intense = "starting".
    3. IF User continues topic -> Status = "continuing".
       - AND user provides more detail -> Intense = "growing".
       - AND user screams/cries/demands -> Intense = "request_high_urgency".
    4. **IMPORTANT**: Intense can NEVER decrease within the same topic.
    ### INSTRUCTIONS
    1. **Style**: Use natural Vietnamese for Gen Z/Alpha. Use words like "nh·ªâ", "n√®", "ui", "ƒë√¢u √°", "th∆∞∆°ng gh√™". 
    2. **Structure**:
       - Step 1: Validate feelings (e.g., "Nghe chuy·ªán n√†y Mimi th·∫•y th∆∞∆°ng em qu√°/...").
       - Step 2: Gentle advice (based on Strategy).
       - Step 3: Check-in (e.g., "Em th·∫•y sao v·ªÅ √Ω n√†y?").
    3. **Constraints**:
       - MAX 3-4 sentences. Keep it short like a chat message.
       - Use 1-2 soft emojis (üåø, ‚òÅÔ∏è, ‚ú®, üíô). Avoid "loud" emojis (üòÇ, ü§£) unless the user is happy.
       - NEVER sound like a textbook or a robot.
       - {f"AVOID: {', '.join(must_not_do)}" if must_not_do else ""}
    """

    else: 
        system_instruction = f"""B·∫°n l√† Mimi - tr·ª£ l√Ω ·∫£o ƒë·ªìng h√†nh c√πng h·ªçc sinh tr∆∞·ªùng THCS Gia Thanh.
        Nhi·ªám v·ª•: L·∫Øng nghe, th·∫•u hi·ªÉu, v√† ƒë·ªìng h√†nh c√πng em.

        C·∫£m x√∫c c·ªßa em: {emotion_status}
        V·∫•n ƒë·ªÅ: {problem if problem else "Ch∆∞a r√µ"}

        Ph∆∞∆°ng ph√°p: {solution}
        Gi·ªçng ƒëi·ªáu: {tone}

        ###KH√îNG ƒë∆∞·ª£c l√†m:
        {chr(10).join(f"- {item}" for item in must_not_do) if must_not_do else "- Ph√°n x√©t, ƒë∆∞a ra l·ªùi khuy√™n y t·∫ø"}
        ### VARIETY RULES
        - KH√îNG l·∫∑p l·∫°i c√¢u m·ªü ƒë·∫ßu gi·ªëng h·ªát tin nh·∫Øn tr∆∞·ªõc.
        - N·∫øu tin nh·∫Øn tr∆∞·ªõc ƒë√£ "Validate feelings" r·ªìi, tin nh·∫Øn n√†y h√£y ƒëi th·∫≥ng v√†o v·∫•n ƒë·ªÅ.
        - ƒê·ª´ng l√∫c n√†o c≈©ng "Mimi th·∫•y th∆∞∆°ng em qu√°". H√£y d√πng: "Ch√†, ca n√†y kh√≥ nh·ªâ", "Mimi hi·ªÉu m√†", "C·ªë l√™n nh√©", v.v.
        ###Quy t·∫Øc ph·∫£n h·ªìi:
        - Ph·∫£n √°nh c·∫£m x√∫c em ƒëang tr·∫£i qua
        - X√°c nh·∫≠n c·∫£m x√∫c c·ªßa em l√† h·ª£p l√Ω
        - ƒê·∫∑t 1 c√¢u h·ªèi m·ªü ƒë·ªÉ em chia s·∫ª th√™m
        - Gi·ªØ gi·ªçng ƒëi·ªáu ·∫•m √°p, kh√¥ng √°p ƒë·∫∑t
        - ƒê·ªô d√†i: 2-4 c√¢u ng·∫Øn
        - Emoji: 1-2 emoji nh·∫π nh√†ng
    """
    
    generation_prompt = f"""{system_instruction}
### SOURCE KNOWLEDGE
    N·∫øu c√≥ th√¥ng tin d∆∞·ªõi ƒë√¢y, h√£y D√ôNG N√ì ƒë·ªÉ ƒë∆∞a ra l·ªùi khuy√™n c·ª• th·ªÉ, ƒë·ª´ng tr·∫£ l·ªùi chung chung:
    [Ki·∫øn th·ª©c chuy√™n gia]: {rag_solution}
**NG·ªÆ C·∫¢NH CU·ªòC TR√í CHUY·ªÜN:**
    {json.dumps(summary_data, ensure_ascii=False, indent=2) if summary_data else "Cu·ªôc tr√≤ chuy·ªán m·ªõi"}

**TIN NH·∫ÆN C·ª¶A EM:**
    "{user_message}"

---

**Y√äU C·∫¶U CU·ªêI:**
- G·ªçi em b·∫±ng "em" ho·∫∑c "b·∫°n"
- T·ª± x∆∞ng l√† "Mimi" ho·∫∑c "m√¨nh"
- Ph√π h·ª£p l·ª©a tu·ªïi 10-16
- Ng√¥n ng·ªØ Ti·∫øng Vi·ªát t·ª± nhi√™n
- Tr√°nh thu·∫≠t ng·ªØ ph·ª©c t·∫°p
- GI·ªÆ NG·∫ÆN G·ªåN NH∆ØNG PH·∫¢I S√öC T√çCH

FINALLY: RETURN EXACT JSON FORMAT:
{{
    "response": ""
}}
RETURN JSON ONLY."""
    
    try:
        response = await llm.ainvoke(generation_prompt)
        cleaned_content = strip_markdown_json(response.content)
        data = json.loads(cleaned_content)
        
        # ‚úÖ L∆∞u solution v·ª´a d√πng ƒë·ªÉ tr√°nh l·∫∑p l·∫°i l·∫ßn sau
        if rag_solution:  # Ch·ªâ save n·∫øu c√≥ d√πng RAG solution
            await redis.set(f"rag:solution:{user_id}", rag_solution, ex=5*60)

        return {
            **state,
            "response": {
                "output": data.get("response", "Xin l·ªói, Mimi hi·ªán kh√¥ng th·ªÉ h·ªó tr·ª£ b·∫°n l√∫c n√†y!")
            }
        }

    except Exception as e:
        logger.error(f"[generate_response] Error: {str(e)}")
        return {
            **state,
            "response": {
                "output": "Xin l·ªói, Mimi hi·ªán kh√¥ng th·ªÉ h·ªó tr·ª£ b·∫°n l√∫c n√†y!"
            }
        }
async def is_urgent(state: State):
    urgency = state["risk"]["urgency"]
    crisis_level = state["user_emotion"].get("crisis_level", "low")
    if urgency == "immediate" and crisis_level in ["high", "critical"]: 
        return "response_emergency"
    else:
        return "should_rotate_plan"
async def response_and_update(state: State):
    update_mem_task = update_cache(state)
    response_task = generate_response(state)
    _, response_state = await asyncio.gather(update_mem_task, response_task)
    return response_state
async def response_emergency(state: State):
    """Node x·ª≠ l√Ω t√¨nh hu·ªëng kh·∫©n c·∫•p - g·ª≠i response v√† th√¥ng b√°o email"""
    
    # L·∫•y th√¥ng tin t·ª´ state
    user_id = state["conversation"]["user_id"]
    user_message = state["conversation"]["messages"][-1]["content"]
    emotion_status = state["user_emotion"]["status"]
    problem = state["user_emotion"]["problem"]
    urgency = state["risk"]["urgency"]
    
    # G·ª≠i email th√¥ng b√°o kh·∫©n c·∫•p (kh√¥ng ch·ªù k·∫øt qu·∫£ ƒë·ªÉ kh√¥ng block workflow)
    asyncio.create_task(
        send_emergency_email(
            user_id=user_id,
            user_message=user_message,
            emotion_status=emotion_status,
            problem=problem,
            urgency=urgency
        )
    )
    
    logger.warning(f"üö® EMERGENCY triggered for user {user_id} - Email notification sent")
    
    return {
        **state,
        "response":{
            "output":"""
M√¨nh r·∫•t ti·∫øc khi nghe b·∫°n ƒëang tr·∫£i qua ƒëi·ªÅu n√†y üíî
C√≥ v·∫ª nh∆∞ l√∫c n√†y b·∫°n ƒëang c·∫£m th·∫•y r·∫•t kh√≥ khƒÉn, v√† c·∫£m gi√°c ƒë√≥ ho√†n to√†n kh√¥ng sai.

B·∫°n kh√¥ng c·∫ßn ph·∫£i ƒë·ªëi m·∫∑t v·ªõi chuy·ªán n√†y m·ªôt m√¨nh. N·∫øu c√≥ th·ªÉ, b·∫°n h√£y th·ª≠ chia s·∫ª v·ªõi ng∆∞·ªùi l·ªõn m√† b·∫°n tin t∆∞·ªüng nh∆∞ b·ªë m·∫π, th·∫ßy c√¥, ho·∫∑c ng∆∞·ªùi th√¢n nh√©.
M√¨nh c√≥ th·ªÉ gi√∫p b·∫°n li√™n h·ªá v·ªõi:
- *c√¥ Th√∫y (hotline: 0962186108)* 
- *c√¥ Tr√¢m (hotline: 0915266338)* 
- *T·ªïng ƒë√†i Qu·ªëc gia B·∫£o v·ªá Tr·∫ª em (111)*
ƒë·ªÉ ch√∫ng ta c√πng nhau v∆∞·ª£t qua v·∫•n ƒë·ªÅ c·ªßa b·∫°n nh√©!

ƒêi·ªÅu quan tr·ªçng nh·∫•t l√†: *b·∫°n x·ª©ng ƒë√°ng ƒë∆∞·ª£c l·∫Øng nghe v√† ƒë∆∞·ª£c gi√∫p ƒë·ª°* üå±
Mimi v·∫´n ·ªü ƒë√¢y ƒë·ªÉ l·∫Øng nghe b·∫°n.
            """
        }
    }
